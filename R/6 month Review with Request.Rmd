---
title: "Two Request and a 6 Month Report on LJC"
author: "Found in this document is an update on the requests by Amy. Followed by a 6 month overview of some of the jobseeker data. Attached to the email you will find a .csv file for the 153 new members to the LJC web. Feel free to send me an email about question or anything else you might need."
date: "April 4, 2018"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Requests

**Report 1:**
All job seekers without matches. Really need their registration source included in the report so that I can check the DXC separately.

**Status:** *Complete* (Found in LJCUserNoMatches.csv)
      
**Report 2:**
I need the zip code location of all job seekers registered between 3/3-3/9 and perhaps a heat map or location-identified map along with it.

**Status:** *Complete* (Found in Request2.csv)

**WARNING** Postal Code, Zip Code and City/State isn't being collected properly and this bug is being worked on.

Below is a chart of the path on, which there are no matches followed by number of resumes completed in this group and then it is showing the count per page per resume completed or not with a percentage. 

```{r, include = FALSE, echo=FALSE}
No_Matches = read.csv('C:/Users/Jerem/Downloads/JS_WithOMatches.csv', header = TRUE)
No_Matches$Matches <- 0
#colnames(No_Matches)
No_Matches <- No_Matches[ , -c(1:2, 4:6, 8)]

d4 = read.csv('C:/Users/Jerem/Downloads/jobseekers_20180413.csv', header = TRUE)
No_Matches <- merge(x=No_Matches,  y=d4, 
                     by.x = "Email",
                     by.y = "Email",
                     all.x = TRUE,
                     all.y = FALSE)
```


```{r, echo=FALSE, include = FALSE, warning=FALSE}
library(tinytex)
library(lubridate)
library(dplyr)
library(urltools)
str(No_Matches$RegistrationSource)
names(No_Matches) <- tolower(names(No_Matches))

#We need to get the date match the pattern before we can actaully get anything done so we will make objects to allow this to happen. 

date.string <- No_Matches$dateregistered
head(No_Matches$dateregistered)
str(No_Matches$dateregistered)
No_Matches$dateregistered <- as.character(No_Matches$dateregistered)

#Website to see the different type of patterns used: #https://stat.ethz.ch/R-manual/R-devel/library/base/html/strptime.html
date.time <- strptime(date.string, format = "%Y-%m-%d %H:%M:%S")

#To help Subesetting we can put this together to allow years to be sepearted with ease
date.year  <- year(date.time)
date.month <- month(date.time)

#add to data set
No_Matches$Reg.Date  <- date.time
No_Matches$Year.Reg  <- date.year
No_Matches$Month.Reg <- date.month
colnames(No_Matches)

No_Matches$Reg.Date <- as.Date(No_Matches$Reg.Date)
Url_Source <- No_Matches$registrationsource
Url_Source <- as.character(Url_Source)

library(urltools)
url_breakdown <- url_parse(Url_Source)
url_breakdown <- subset(url_breakdown, select = c("path")) 
No_Matches<- cbind(No_Matches, url_breakdown)
```

```{r, echo=FALSE, warning=FALSE}
No_Matches %>% 
  group_by(path) %>%
  summarise(
    count = n()
  ) %>% arrange(desc(count))

No_Matches %>% 
  group_by(resumecompletefl) %>%
  summarise(
    count = n()
  ) %>% arrange(desc(count))

No_Matches %>% 
  group_by(path, resumecompletefl) %>%
    summarise(
    count = n()
  ) %>% group_by(path) %>%
  mutate(paste0(PerResumeComp = round(100*(count/ sum(count)),2), "%")) %>% arrange(path)
  

#write.csv(No_Matches, file = 'C:/Users/Jerem/Downloads/LJCUserNoMatches.csv')
#write.csv(PagePath_NoMatches, file = 'C:/Users/Jerem/Downloads/PagePathNoMatches.csv')
#write.csv(PercentageResumesComp, file = 'C:/Users/Jerem/Downloads/PercentageResumesComp.csv')
```

## Location of New Users

*Done in Tableau I will look into how to fix the bug in R. See email for picture*

Charts are describing LJC During 3/3-9/2018

```{r, include = FALSE, echo=FALSE}
d1 = read.csv("C:/Users/Jerem/OneDrive/Documents/Vinformatix/Vinformatix_Knowledge_Transfer/LJC/Monthly Reporting/March_2018/jobseekers.csv", header = TRUE)

No_Matches = read.csv('C:/Users/Jerem/Downloads/JS_WithOMatches.csv', header = TRUE)
#colnames(No_Matches)
No_Matches <- No_Matches[ , -c(1:2, 4:6, 8)]
No_Matches$Matches = 0
d1 <- merge(x=d1,  y=No_Matches, 
                     by.x = "Email",
                     by.y = "Email",
                     all.x = TRUE,
                     all.y = FALSE)
table(is.na(d1$Matches))
d1$Matches  <- ifelse(is.na(d1$Matches), 1, d1$Matches)
rm(No_Matches)
```

```{r, echo=FALSE, include = FALSE, warning=FALSE}
library(tinytex)
library(lubridate)
library(dplyr)
library(urltools)
#str(d1$RegistrationSource)
names(d1) <- tolower(names(d1))

#We need to get the date match the pattern before we can actaully get anything done so we will make objects to allow this to happen. 

date.string <- d1$dateregistered
head(d1$dateregistered)
str(d1$dateregistered)
d1$dateregistered <- as.character(d1$dateregistered)
date.time <- strptime(date.string, format = "%Y-%m-%d %H:%M:%S")

#To help Subesetting we can put this together to allow years to be sepearted with ease
date.year  <- year(date.time)
date.month <- month(date.time)

#add to data set
d1$Reg.Date  <- date.time
d1$Year.Reg  <- date.year
d1$Month.Reg <- date.month
#colnames(d1)
#deleting useless columns changes depending on the SQL query they choose
#d1 <- d1[ , -c(2:5,8,12:21)]

#Looking at the last month needs to change every month
date1 <- as.Date("2018-03-03")
date2 <- as.Date("2018-03-09")
interval <- interval(date1, date2)

d1$Reg.Date <- as.Date(d1$Reg.Date)
d1 <- d1[d1$Reg.Date %within% interval,]
Url_Source <- d1$registrationsource
Url_Source <- as.character(Url_Source)

library(urltools)
url_breakdown <- url_parse(Url_Source)
url_breakdown <- subset(url_breakdown, select = c("path")) 
d1<- cbind(d1, url_breakdown)
```

```{r, echo=FALSE, warning=FALSE}
cities <- read.csv("C:/Users/Jerem/OneDrive/Documents/Practicum/uszipecodes.csv", header = TRUE)

#allows names to be lowered
d1$current.city <- tolower(d1$current.city)
d1$current.city <-trimws(d1$current.city, which = "both")
cities$city <- tolower(cities$city)

#colnames(d1)

d1 <- merge(x=d1,y=cities, 
                  by.x = c("current.city", "current.state"),
                  by.y = c("city", "state_id"),
                  all.x = TRUE,
                  all.y = FALSE)



write.csv(d1, file = 'C:/Users/Jerem/Downloads/Request2.csv')
```

```{r, echo=FALSE, include = FALSE, warning=FALSE}
library(ggplot2)
d2 <- subset(d1, !is.na(d1$lat))

d2$path <- as.factor(d2$path)
d1$path <- as.factor(d1$path)

#ggplot(d2, aes(lng, lat, colour = path)) + 
# borders("state")+
#  geom_point() +
#  coord_quickmap()+
#  theme_classic()+
#  ggtitle("Registration For LJC During 3/3-9/2018")+
#  labs(colour = "Reg Source")

```

```{r, echo=FALSE, warning=FALSE}
library(tinytex)
d1 %>%
  group_by(d1$current.state) %>%
  tally() 

d1 %>%
  group_by(d1$path) %>%
  tally() %>%
  arrange(desc(n))

d1 %>%
  group_by(d1$postalcode) %>%
  tally() %>%
  arrange(desc(n))

```

## Information Regarding Resumes & Other 
(**New LJC Members Over The Last 6 Months**)

*Some of this is repeated data from before, it is a cleaned up version with more graphs and some thoughts*

    - How the resume was added (if added – upload or manual) (Pending)
    - Link to resume (if added) (Pending)
    - Whether profile is public or private (Pending)

```{r, echo=FALSE, include=FALSE, warning=FALSE}
library(tinytex)
library(lubridate)
library(dplyr)
job.seeker <- read.csv("C:/Users/Jerem/OneDrive/Documents/Vinformatix/Vinformatix_Knowledge_Transfer/LJC/Monthly Reporting/March_2018/jobseekers.csv", header = T)

names(job.seeker) <- tolower(names(job.seeker))

#We need to get the date match the pattern before we can actaully get anything done so we will make objects to allow this to happen. 

date.string <- job.seeker$dateregistered
head(job.seeker$dateregistered)
str(job.seeker$dateregistered)
job.seeker$dateregistered <- as.character(job.seeker$dateregistered)

#Website to see the different type of patterns used: #https://stat.ethz.ch/R-manual/R-devel/library/base/html/strptime.html
date.time <- strptime(date.string, format = "%Y-%m-%d")

#To help Subesetting we can put this together to allow years to be sepearted with ease
date.year  <- year(date.time)
date.month <- month(date.time)

#add to data set
job.seeker$Reg.Date  <- date.time
job.seeker$Year.Reg  <- date.year
job.seeker$Month.Reg <- date.month
Url_Source <- job.seeker$registrationsource
Url_Source <- as.character(Url_Source)

library(urltools)
url_breakdown <- url_parse(Url_Source)
url_breakdown <- subset(url_breakdown, select = c("path")) 
job.seeker<- cbind(job.seeker, url_breakdown)
#colnames(job.seeker)
#deleting useless columns changes depending on the SQL query they choose
job.seeker <- job.seeker[ , -c(4,6:7,11:21,27,29,33,35:36)]
rm(Url_Source, url_breakdown)

#Looking at the last month needs to change every month
date1 <- as.Date("2017-11-01")
date2 <- as.Date("2018-03-31")
interval <- interval(date1, date2)

job.seeker$Reg.Date <- as.Date(job.seeker$Reg.Date)
Last6.added <- job.seeker[job.seeker$Reg.Date %within% interval,]
Url_Source <- Last6.added$registrationsource
Url_Source <- as.character(Url_Source)

#Resume
date.string <- Last6.added$resume.post.date
Last6.added$resume.post.date <- as.character(Last6.added$resume.post.date)
date.time <- strptime(date.string, format = "%Y-%m-%d")
Last6.added$Resume.Date  <- date.time

#Access
date.string <-Last6.added$profile.accessed
Last6.added$profile.accessed <- as.character(Last6.added$profile.accessed)
date.time <-strptime(date.string, format = "%m/%d/%Y")
Last6.added$access.Date <-date.time
#colnames(Last6.added)
Last6.added <- Last6.added[, -c(5,10,15)]

#Subset Resumes/Non-Resumes
df <- subset(Last6.added, Last6.added$resumecompletefl == 1)
df_na <- subset(Last6.added, Last6.added$resumecompletefl == 0)
rm(job.seeker, date.month, date.string, date.year, date1, date2, interval, date.time,Url_Source)

#Note there is system error with ljc picking up resumes before registration dates 
df$Res_lapse <- round(difftime(df$Resume.Date, df$Reg.Date, units = "days"),1)
df$Res_lapse  <- as.numeric(df$Res_lapse)
df$Res_lapse  <- ifelse(df$Res_lapse < 1, 0, df$Res_lapse)
df$rightaway <- ifelse(df$Res_lapse  == 0, "1", "0")
```

## **Who Is Completing Their Resumes**

- A Breakdown of degree type and Resume Completion.

- If I am correct, it looks as though "Jobseeker-Events", "DXC Technology Nola" and "Globalstar"", which I believe are events. Even if the last two aren't there is still much higher rate of resumes not being completed with jobseeker events. I know we have pushed a more mobile friendly version so this will be interesting to see if these changes change the resume completition. 

```{r, echo=FALSE, warning=FALSE}
library(ggplot2)
#colnames(Last6.added)
Last6.added$access.Date <- as.POSIXct(Last6.added$access.Date)
Last6.added$Resume.Date <- as.POSIXct(Last6.added$Resume.Date)
Last6.added$resumecompletefl= as.factor(Last6.added$resumecompletefl)
Last6.added$degree = as.character(Last6.added$degree)
Last6.added$degree[Last6.added$degree==" "]<-"Missing"
Last6.added$degree = as.factor(Last6.added$degree)

Last6.added %>%
  subset(!(Last6.added$degree == "Missing")) %>%
  group_by(resumecompletefl,degree) %>%
  summarise(
    count = n()
  )%>% group_by(degree)%>%
  mutate(freq = paste0(round(100 * (count / sum(count)),2), "%")) %>%
  filter(count>0) %>% arrange(degree)%>%
  ggplot( aes(x = resumecompletefl, y = count, fill = degree)) +
  geom_bar(stat = "identity", color = "black")+
  geom_text(aes(label = freq, vjust= 1))+
  facet_wrap(~degree, scale = "free_y")+ 
  theme_light() + 
  theme(legend.position = "none")+
  labs(title = "Resume Completed By Degree Type",
       caption = "1 = Resume Completed & 0 = Resume Incomplete", 
       x = "Resume Complete Or Not")

Last6.added %>%
  group_by(resumecompletefl,path) %>%
  summarise(
    count = n()
  ) %>% group_by(path) %>%
  mutate(freq = paste0(round(100 * (count/sum(count)),2), "%"))%>%
  filter(count > 0 ) %>% arrange(desc(count))%>%
  ggplot( aes(x = resumecompletefl, y = count, fill = path)) +
  geom_bar(stat = "identity", color = "black")+
  geom_text(aes(label = freq, vjust= 1))+
  facet_wrap(~path, scale = "free_y")+ 
  theme_light() + 
  theme(legend.position = "none")+
  labs(title = "Resume Completed By Page Path",
       caption = "1 = Resume Completed & 0 = Resume Incomplete", 
       x = "Resume Complete Or Not")

```

## **LJC Activity, Time it Takes For Resumes to be Completed & Time Since Last Visit**

-	Of the 5,018 added members of the LJC website 42% of the new members have completed their resumes.

    - From my understanding if there isn't a completed resume then each they can recieve is zero meaning that more than 50% of the recuirtment of employees is lost because resumes aren't being fully completed. 

-	Of that 42% (2152 members) 86% percent of them are posting and completing their resumes right away.  You can see from the chart below by registration source, which groups are taking longer as whole to post. 

    - Of the 2152 LJC members that have completed their resumes 1857 of them completed them on the day of sign up. 293 of them came back and finished them. 
    
    - The 293 members here are the quantiles of when they come back to finish their resumes. The largest amount of time fo an individual to come back and finish their resume was 122.  In the sub-group the mean time to complete thier resume was 13.59 days. With their being a couple outliers a more reliable metric is 3.20 is a better metric as you have a couple large outliers pulling the mean. 

```{r  ,include=FALSE, echo=FALSE, warning=FALSE}
library(dplyr)
df$access.Date <- as.POSIXct(df$access.Date)
df$Resume.Date <- as.POSIXct(df$Resume.Date)
table(df$rightaway)
summary(df$Res_lapse)

df$Res_lapse %>%
  subset(df$Res_lapse > 1 & df$Res_lapse < 20) %>%
  summary(df$Res_lapse)

```


```{r, echo=FALSE, warning=FALSE}
library(ggplot2)
df %>%
  subset(df$Res_lapse >1) %>%
  ggplot(aes(x = Res_lapse)) +
  geom_bar(color = "blue")+
  theme_light()+
  labs(title = "Distrubtion of Lasped Time In Day for Resume Completion",
       subtitle = "LJC Members", x = "Lapsed Time In Days", y ="Frequency")

df%>% 
  group_by(path) %>%
  summarise(
    Total = n(),
    Average_Time = round(mean(Res_lapse),2)
  ) %>%
  arrange(desc(Average_Time))

ggplot(subset(df, !(df$Res_lapse<= 3)), aes(y =Res_lapse, x = path, color = path))+
  geom_boxplot()+
  theme_light()+
  ggtitle("Number of Days by Reg Source to Complete Thier Resume", 
          "Showing only Observations with Days Lasped of 3 or greater")+
  xlab("Registration Source")+
  ylab("Number Of Days")+ 
  theme(axis.text.x = element_text(angle = 50, hjust = 1, size = 7))
```


## **Looking At The Number of Applications**

A surprising stat came about from this exploration and that is there are more applications being sent out by individuals that haven’t come back to the LJC site than ones that have come back. The proportion of applicants to number of apps is higher for those that come back, but that should be expected as they are active users. Being active suggests that you are actively looking for a job or are in the market to change careers.

-	Of the 2152 new LJC members with resumes 469 of them have come back to the site since registration and have applied to 165 jobs. The other 1683 members had applied to 366 jobs the day of registration but haven’t made it back to the site.  

```{r, echo=FALSE, warning=FALSE}
df_na$Res_lapse <- -1
df_na$rightaway <- -1
df_na$Membership_days <- 0
df_na$visit_laspe <- -1
df_na$Re_Visit <- 0
df_na$Days <- -1

#Calcuate How Many Days This Indvidual Has Been A Member
df$Membership_days <- round(difftime(Sys.Date(), df$Reg.Date, units = "days"),0)
#df$Membership_days <- ifelse(df$Membership_days < 1, 0, df$Membership_days)
df$Membership_days <- as.numeric(df$Membership_days)

#Time since they were last on the LJC Website
df$visit_lapse <- round(difftime(Sys.Date(), df$access.Date, units = "days"), 0)
df$visit_lapse <- ifelse(df$visit_lapse < 1, 0, df$visit_lapse)
df$visit_lapse <- as.numeric(df$visit_lapse)


df$Re_Visit <- ifelse(df$Membership_days == df$visit_lapse, 0, 1)
#Metric to messure if the number of days between last visit and membership days 
#This is going to give us a metric to know how long since they signed up and their last visit
#ie: if you have 87 days it means that you became a memember 87 days ago and have come back x amount of days later
#Kinda of a metric to give us an idea of how many people come back (Explore this more later)
df$Days <- df$Membership_days - df$visit_lapse

#table(df$Re_Visit)

#mean(df$visit_lapse)

df %>% 
  group_by(df$Re_Visit) %>%
  summarise(
    Total = n(),
    Avg_LastVisit = mean(visit_lapse),
    Apps_Sent = sum(applicationcount)
  )

df$check<-as.factor(df$Re_Visit)
```



```{r  , echo=FALSE}
library(ggplot2)
ggplot(df, aes(visit_lapse, fill = path)) +
  stat_bin(geom = "bar", bins = 50, alpha = .58)+
  facet_wrap(~path, scales="free_y")+
  theme_light()+
  theme(legend.position ="none")+
  labs(title = "Distrubtion of Time Since Last Visit In Days")

 df %>% 
  group_by(path) %>% 
  summarise(
    n = n(), 
    min = min(visit_lapse), 
    max = max(visit_lapse), 
    mean = mean(visit_lapse),
    median = median(visit_lapse),
    Apps = sum(applicationcount)
  ) %>%
   arrange(desc(mean))

plot <-  df %>% 
  group_by(path) %>% 
  summarise(
    n = n(), 
    min = min(visit_lapse), 
    max = max(visit_lapse), 
    mean = mean(visit_lapse),
    median = median(visit_lapse),
    Apps = sum(applicationcount)
  ) %>%
   arrange(desc(mean))

```


```{r, echo=FALSE, warning=FALSE}
ggplot(plot, aes(x = reorder(path, -mean), y = n, fill = path)) +
  geom_bar(stat = "identity")+
  xlab("Reg Source")+
  geom_text(aes(label= round(mean), vjust=-.3))+
  theme_light()+
  theme(axis.text.x = element_text(angle = 40, hjust = 1, size = 7), legend.position = "none")+
  labs(title = "Ordered by Average Days Since Last Visiting LJC", 
       subtitle = "Numbers Above Bars Represents the Mean Days Since Logging Back on LJC",
       x = "Registration source", y = "Amount Of LJC Members")
```

## The End 

I just wanted to see if this kind of report gets you thinking of anything else that you would like me to look into more carefully. 

I hope you enjoyed, 

Jeremy Demlow 
