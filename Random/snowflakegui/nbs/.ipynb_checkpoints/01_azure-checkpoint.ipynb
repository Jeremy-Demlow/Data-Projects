{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp azure.filehandling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_azure.ipynb.\n",
      "Converted 02_utils_parseyaml.ipynb.\n",
      "Converted 03_utils_dataframes.ipynb.\n",
      "Converted 04_dstools_preparedata.ipynb.\n",
      "Converted 05_snowflake_query.ipynb.\n",
      "Converted 06_snowflake_copyinto.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ``FileHandling``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What is Azure Blob? \n",
    "\n",
    "Azure Blob storage is Microsoft's object storage solution for the cloud. Blob storage is optimized for storing massive amounts of unstructured data, such as text or binary data.\n",
    "\n",
    "Blob storage is ideal for:\n",
    "\n",
    "- Serving images or documents directly to a browser\n",
    "\n",
    "- Storing files for distributed access\n",
    "\n",
    "- Streaming video and audio\n",
    "\n",
    "- Storing data for backup and restore, disaster recovery, and archiving\n",
    "\n",
    "- Storing data for analysis by an on-premises or Azure-hosted service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from easymigration.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FileHandling:\n",
    "    def __init__(self, connection_string, logger=logger):\n",
    "        self.blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    \"\"\"\n",
    "    file handling for all DSDE Azure blob storage. Both upload and download\n",
    "    have there own clients with in this class so that they can call different\n",
    "    containers with in the storage account within on init. This is designed,\n",
    "    but can be removed if we still this to be a waste.\n",
    "    Args:\n",
    "        connection_string (str): azure connection string to blob storage\n",
    "        logger: logging choices can be overwritten if you want the defaults\n",
    "    \"\"\"\n",
    "\n",
    "    def upload(self,\n",
    "               container_name: str,\n",
    "               file_path: str,\n",
    "               dest: str = '',\n",
    "               overwrite: bool = False):\n",
    "        \"\"\"\n",
    "        uploads file(s) to azure blob storage\n",
    "        Args:\n",
    "            container_name (str): azure blob container name\n",
    "            file_path (str): file or directory to upload to azure\n",
    "            dest (str, optional): destination in azure/ file name in azure. Defaults to ''.\n",
    "            overwrite (bool, optional): write over same file names. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.container_name = container_name\n",
    "        self.container_client = self.blob_service_client.get_container_client(container_name)\n",
    "        self.create_blob_container(container_name=container_name)\n",
    "        if (os.path.isdir(file_path)):\n",
    "            self.load_dir = True\n",
    "            self.upload_dir(file_path, overwrite)\n",
    "        else:\n",
    "            self.load_dir = False\n",
    "            self.upload_file(file_path, dest, overwrite)\n",
    "\n",
    "    def upload_file(self,\n",
    "                    file_path: str,\n",
    "                    blob_name: str,\n",
    "                    overwrite=False):\n",
    "        \"\"\"\n",
    "        simply uploads a file to blob storage\n",
    "        Args:\n",
    "            file_path (str): file to blob\n",
    "            blob_name (str): destination in blob\n",
    "            overwrite (bool, optional): write over same file names. Defaults to False.\n",
    "        \"\"\"\n",
    "        logger.info(f'Uploading {file_path}, to to Azure Storage {blob_name}')\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            try:\n",
    "                blob_name = file_path if self.load_dir is True else blob_name\n",
    "                self.container_client.upload_blob(data=file, name=blob_name, overwrite=overwrite)\n",
    "            except Exception as e:\n",
    "                logger.error(f'\"Error Message: {e.error_code.value}\"')\n",
    "        logger.info('Azure Upload Complete')\n",
    "\n",
    "    def upload_dir(self,\n",
    "                   directory: str,\n",
    "                   overwrite: bool = False):\n",
    "        \"\"\"\n",
    "        simply uploads a directory to azure blob note with python\n",
    "        we can have arguement be used from upload will figure\n",
    "        that out hopefully\n",
    "        Args:\n",
    "            directory (str): directory that is being moved to blob\n",
    "            overwrite (bool, optional): write over same file names. Defaults to False.\n",
    "        \"\"\"\n",
    "        prefix = os.path.basename(directory) + '/'\n",
    "        # Walk Through Directory\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for name in files:\n",
    "                # root, director == . when at root level of moved directory\n",
    "                dir_part = os.path.relpath(root, directory)\n",
    "                dir_part = '' if dir_part == '.' else dir_part + '/'\n",
    "                file_path = os.path.join(root, name)\n",
    "                blob_path = prefix + dir_part + name\n",
    "                self.upload_file(file_path, blob_path)\n",
    "\n",
    "    def create_blob_container(self,\n",
    "                              container_name: str = str(uuid.uuid4()),\n",
    "                              unique: bool = False):\n",
    "        \"\"\"\n",
    "        creates/check for container when ``upload`` is called, but\n",
    "        this function can be used seperately to create\n",
    "        a new container in isolation within the specific storage account\n",
    "        Args:\n",
    "            container_name (str, optional): creates azure blob container name. Defaults to str(uuid.uuid4()).\n",
    "            unique (bool, optional): add a unique tail to container name. Defaults to False.\n",
    "        \"\"\"\n",
    "        regex = re.compile(r'[@_!#$%^&*()<>?/\\|}{~:]')\n",
    "        # Check if container_name is valid\n",
    "        if (regex.search(container_name) is None):\n",
    "            logger.info(f'{container_name} is a valid')\n",
    "        else:\n",
    "            container_name = re.sub(r'[\\W_]+', '', container_name)\n",
    "            logger.info(f'container_name changed to {container_name}')\n",
    "        if unique:\n",
    "            container_name = container_name + str(uuid.uuid4())\n",
    "        else:\n",
    "            container_name = container_name\n",
    "        # Current Python SDK doesn't support exist\n",
    "        try:\n",
    "            # Create the container\n",
    "            _ = self.blob_service_client.create_container(container_name)\n",
    "        except Exception as e:\n",
    "            logger.info(f'{e.error_code.value}')\n",
    "\n",
    "    def download(self,\n",
    "                 blob_location: str,\n",
    "                 dest: str,\n",
    "                 container_name: str,\n",
    "                 blob_path: str = '',\n",
    "                 directory: str = None,\n",
    "                 recursive: bool = True,\n",
    "                 overwrite: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            blob_location (str): location in container\n",
    "            dest (str): local destination of file\n",
    "            container_name (str): azure blob container name.\n",
    "            blob_path (str, optional): path in blob helps search. Defaults to ''.\n",
    "            directory (str, optional): not useful. Defaults to None.\n",
    "            recursive (bool, optional): helps with search for file can be false if blob_path is known. Defaults to True.\n",
    "            overwrite (bool, optional): write over same file names. Defaults to False.\n",
    "        \"\"\"\n",
    "        if not dest.endswith('/'):\n",
    "            dest += '/'\n",
    "        if blob_location.endswith('/'):\n",
    "            if blob_path == '':\n",
    "                blobs = self.ls_blob(container_name=container_name, path=blob_path, recursive=recursive)\n",
    "                blobs = [blobs for blobs in blobs if os.path.basename(os.path.normpath(blob_location)) in blobs]\n",
    "            else:\n",
    "                blobs = self.ls_blob(container_name=container_name, path=blob_path, recursive=recursive)\n",
    "                blobs = [blob_location + blob for blob in blobs]\n",
    "            if directory and not directory.endswith('/'):\n",
    "                directory += '/'\n",
    "            for blob in blobs:\n",
    "                logger.info(f'Downloading {blob}')\n",
    "                if directory:\n",
    "                    self.download_file(container_name, blob, os.path.join(dest, directory), overwrite)\n",
    "                else:\n",
    "                    self.download_file(container_name, blob, dest, overwrite)\n",
    "        else:\n",
    "            self.download_file(container_name, os.path.basename(os.path.normpath(blob_location)), dest, overwrite)\n",
    "        logger.info('Download complete')\n",
    "\n",
    "    def download_file(self,\n",
    "                      container_name: str,\n",
    "                      file: str,\n",
    "                      file_path: str,\n",
    "                      overwrite: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            container_name (str): azure blob container name.\n",
    "            file (str): file to download from blob\n",
    "            file_path (str): location to put `file`\n",
    "            overwrite (bool, optional): write over same file names. Defaults to False.\n",
    "        \"\"\"\n",
    "        if file_path.endswith('.'):\n",
    "            file_path += '/'\n",
    "        blob_dest = file_path + os.path.basename(file) if file_path.endswith('/') else file_path\n",
    "        logger.info(f'{file} to {blob_dest}')\n",
    "        if not overwrite:\n",
    "            if os.path.exists(blob_dest):\n",
    "                logger.warning('file path already exist change overwrite to ``True`` if you want to overwrite file')\n",
    "                return\n",
    "        os.makedirs(os.path.dirname(blob_dest), exist_ok=True)\n",
    "        download_client = self.blob_service_client.get_container_client(container_name)\n",
    "        downloader = download_client.get_blob_client(blob=file)\n",
    "        with open(blob_dest, 'wb') as file:\n",
    "            data = downloader.download_blob()\n",
    "            file.write(data.readall())\n",
    "\n",
    "    def ls_blob(self,\n",
    "                container_name: str,\n",
    "                path: str,\n",
    "                recursive: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            container_name (str): azure blob container name.\n",
    "            path (str): blob path to look at\n",
    "            recursive (bool, optional): recurisve look. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            list: file list\n",
    "        \"\"\"\n",
    "        if not path == '' and not path.endswith('/'):\n",
    "            path += '/'\n",
    "        download_client = self.blob_service_client.get_container_client(container_name)\n",
    "        blob_looker = download_client.list_blobs(name_starts_with=path)\n",
    "        files = []\n",
    "        for blob in blob_looker:\n",
    "            relative_path = os.path.relpath(blob.name, path)\n",
    "            if recursive or not '/' in relative_path: # NOQA:\n",
    "                files.append(relative_path)\n",
    "        return files\n",
    "\n",
    "    def rm_files(self,\n",
    "                 container_name: str,\n",
    "                 delete_path: str = '',\n",
    "                 recursive: bool = False):\n",
    "        \"\"\"\n",
    "        removes files from storage account\n",
    "        Args:\n",
    "            container_name (str): azure blob container name.\n",
    "            delete_path (str, optional): what to delete file or directory. Defaults to ''.\n",
    "            recursive (bool, optional): recursive delete. Defaults to False.\n",
    "        \"\"\"\n",
    "        if not delete_path == '' and not delete_path.endswith('/'):\n",
    "            delete_path, delete_file = delete_path.rsplit('/', 1)\n",
    "            delete_path += '/'\n",
    "            blobs = self.ls_blob(container_name, delete_path, recursive)\n",
    "            if delete_file in blobs:\n",
    "                blobs = [delete_file]\n",
    "        else:\n",
    "            blobs = self.ls_blob(container_name, delete_path, recursive)\n",
    "        if not blobs:\n",
    "            logger.warning('location in blob is empty')\n",
    "            return\n",
    "        blobs = [delete_path + blob for blob in blobs]\n",
    "        logger.info(f'files to be removed {blobs}')\n",
    "        delete_client = self.blob_service_client.get_container_client(container_name)\n",
    "        if len(blobs) > 1:\n",
    "            delete_client.delete_blobs(*blobs)\n",
    "        else:\n",
    "            delete_client.delete_blob(*blobs)\n",
    "    \n",
    "    def rm_container(self,\n",
    "                     container_name: str):\n",
    "        \"remove container from storage account\"\n",
    "        self.blob_service_client.delete_container(container_name)\n",
    "        \n",
    "    def ls_containers(self,\n",
    "                      name_starts_with: str = None):\n",
    "        \"show containers in storage account\"\n",
    "        container_names = self.blob_service_client.list_containers(name_starts_with=name_starts_with)\n",
    "        for names in container_names:\n",
    "            print(names['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unlink_files(files: list, file_path: str = './'):\n",
    "    \"\"\"\n",
    "    clean up tool for files that shouldn't be there\n",
    "\n",
    "    Args:\n",
    "        files (list): can be a list of just one file to remove\n",
    "        file_path (str, optional): location of the file. Defaults to './'.\n",
    "    \"\"\"\n",
    "    file_list = files\n",
    "    for x in file_list:\n",
    "        os.unlink(os.path.join(file_path, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"FileHandling\" class=\"doc_header\"><code>class</code> <code>FileHandling</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>FileHandling</code>(**`connection_string`**, **`logger`**=*`<Logger easymigration.imports (INFO)>`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FileHandling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To Use ``FileHandling``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would like to figure how how to get this with out going into the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "connect_str = os.environ['connection_str']\n",
    "fh = FileHandling(connect_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FileHandling.download\" class=\"doc_header\"><code>FileHandling.download</code><a href=\"__main__.py#L109\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FileHandling.download</code>(**`blob_location`**:`str`, **`dest`**:`str`, **`container_name`**:`str`, **`blob_path`**:`str`=*`''`*, **`directory`**:`str`=*`None`*, **`recursive`**:`bool`=*`True`*, **`overwrite`**:`bool`=*`False`*)\n",
       "\n",
       "Args:\n",
       "    blob_location (str): location in container\n",
       "    dest (str): local destination of file\n",
       "    container_name (str): azure blob container name.\n",
       "    blob_path (str, optional): path in blob helps search. Defaults to ''.\n",
       "    directory (str, optional): not useful. Defaults to None.\n",
       "    recursive (bool, optional): helps with search for file can be false if blob_path is known. Defaults to True.\n",
       "    overwrite (bool, optional): write over same file names. Defaults to False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FileHandling.download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists('testing/testing.csv.gz') == False, 'File should not be there'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download calls download_file when downloading directory of files\n",
    "fh.download(blob_location = 'testing.csv.gz',\n",
    "            dest = 'testing',\n",
    "            container_name='testing',\n",
    "            blob_path = '',\n",
    "            directory = None,\n",
    "            recursive = True,\n",
    "            overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists('testing/testing.csv.gz') == True, 'File should be located here'\n",
    "unlink_files(['testing.csv.gz'], './testing')\n",
    "assert os.path.exists('testing/testing.csv.gz') == False, 'File should not be there'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "# download calls download_file when downloading directory of files\n",
    "fh.download(blob_location = 'testing.csv.gz',\n",
    "            dest = 'testing',\n",
    "            container_name='testing',\n",
    "            blob_path = '',\n",
    "            directory = None,\n",
    "            recursive = True,\n",
    "            overwrite = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "# download folder too a specifc folder location and knows what path\n",
    "fh.download(blob_location = 'testing/',\n",
    "            dest = 'downloads/testing_recursive_w_blob_path',\n",
    "            container_name='testing',\n",
    "            blob_path = 'testing',\n",
    "            directory = None,\n",
    "            recursive = False,\n",
    "            overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "# download folder too a specifc folder location and knows what path\n",
    "fh.download(blob_location = 'testing/',\n",
    "            dest = 'downloads/testing_recursive_w_blob_path',\n",
    "            container_name='testing',\n",
    "            blob_path = '', # Takes about 3-10 more seconds when you aren't sure of the path\n",
    "            directory = None,\n",
    "            recursive = True,\n",
    "            overwrite = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "# Example of not knowing where the blob path is and a blank blobpath\n",
    "# Will Work With Recursive as it looks at the whole container and finds your blob location files\n",
    "fh.download(blob_location = 'testing/',\n",
    "            dest = 'downloads/testing_recursive_w_blob_path',\n",
    "            container_name='testing',\n",
    "            blob_path = '',\n",
    "            directory = None,\n",
    "            recursive = False,\n",
    "            overwrite = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FileHandling.download_file\" class=\"doc_header\"><code>FileHandling.download_file</code><a href=\"__main__.py#L148\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FileHandling.download_file</code>(**`container_name`**:`str`, **`file`**:`str`, **`file_path`**:`str`, **`overwrite`**:`bool`=*`False`*)\n",
       "\n",
       "Args:\n",
       "    container_name (str): azure blob container name.\n",
       "    file (str): file to download from blob\n",
       "    file_path (str): location to put `file`\n",
       "    overwrite (bool, optional): write over same file names. Defaults to False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FileHandling.download_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "# download file only\n",
    "fh.download_file(container_name='testing',\n",
    "                 file = 'testing.csv.gz',\n",
    "                 file_path = f'./testing/',\n",
    "                 overwrite=True)\n",
    "unlink_files(['testing.csv.gz'], './testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FileHandling.upload\" class=\"doc_header\"><code>FileHandling.upload</code><a href=\"__main__.py#L15\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FileHandling.upload</code>(**`container_name`**:`str`, **`file_path`**:`str`, **`dest`**:`str`=*`''`*, **`overwrite`**:`bool`=*`False`*)\n",
       "\n",
       "uploads file(s) to azure blob storage\n",
       "Args:\n",
       "    container_name (str): azure blob container name\n",
       "    file_path (str): file or directory to upload to azure\n",
       "    dest (str, optional): destination in azure/ file name in azure. Defaults to ''.\n",
       "    overwrite (bool, optional): write over same file names. Defaults to False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FileHandling.upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dir \n",
    "fh.upload(container_name='easymigrationtest',\n",
    "          file_path='testing/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if files arrived\n",
    "assert fh.ls_blob(container_name='easymigrationtest', path='', recursive=True) == ['testing/test.txt', 'testing/view_test.txt'], 'Test folder should be in azure'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "# Upload root file example\n",
    "# fh.upload(container_name='easymigrationtest', \n",
    "#           file_path='./easymigrationtest.txt', \n",
    "#           dest='dsde_text.txt')\n",
    "# Upload file from local file path and also show if it is there already\n",
    "# To over right change overwrite to `True`\n",
    "# fh.upload(container_name='easymigrationtest', \n",
    "#           file_path='test_folder/test_2/folder_2_test.txt', \n",
    "#           dest='folder_2_test.txt')\n",
    "# Check if files arrived\n",
    "# fh.ls_blob(container_name='easymigrationtest', path='', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FileHandling.rm_files\" class=\"doc_header\"><code>FileHandling.rm_files</code><a href=\"__main__.py#L199\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FileHandling.rm_files</code>(**`container_name`**:`str`, **`delete_path`**:`str`=*`''`*, **`recursive`**:`bool`=*`False`*)\n",
       "\n",
       "removes files from storage account\n",
       "Args:\n",
       "    container_name (str): azure blob container name.\n",
       "    delete_path (str, optional): what to delete file or directory. Defaults to ''.\n",
       "    recursive (bool, optional): recursive delete. Defaults to False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FileHandling.rm_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dir \n",
    "fh.upload(container_name='easymigrationtest',\n",
    "          file_path='testing/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove files from blob\n",
    "# Note: remember when there is only one file in the folder the folder will be deleted\n",
    "fh.rm_files(container_name='easymigrationtest', \n",
    "            delete_path='testing/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert fh.ls_blob(container_name='easymigrationtest', path='', recursive=True) == ['testing/view_test.txt'], 'empty list should be the case'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "# remove folder and all files\n",
    "fh.rm_files(container_name='easymigrationtest',\n",
    "            delete_path='',\n",
    "            recursive=True)\n",
    "\n",
    "# Check if files arrived\n",
    "fh.ls_blob(container_name='easymigrationtest', path='', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FileHandling.rm_container\" class=\"doc_header\"><code>FileHandling.rm_container</code><a href=\"__main__.py#L229\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FileHandling.rm_container</code>(**`container_name`**:`str`)\n",
       "\n",
       "remove container from storage account"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FileHandling.rm_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove container\n",
    "fh.rm_container(container_name='easymigrationtest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FileHandling.ls_blob\" class=\"doc_header\"><code>FileHandling.ls_blob</code><a href=\"__main__.py#L175\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FileHandling.ls_blob</code>(**`container_name`**:`str`, **`path`**:`str`, **`recursive`**:`bool`=*`False`*)\n",
       "\n",
       "Args:\n",
       "    container_name (str): azure blob container name.\n",
       "    path (str): blob path to look at\n",
       "    recursive (bool, optional): recurisve look. Defaults to False.\n",
       "\n",
       "Returns:\n",
       "    list: file list"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FileHandling.ls_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Check if files arrived\n",
    "fh.ls_blob(container_name='easymigrationtest', path='', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FileHandling.ls_containers\" class=\"doc_header\"><code>FileHandling.ls_containers</code><a href=\"__main__.py#L234\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FileHandling.ls_containers</code>(**`name_starts_with`**:`str`=*`None`*)\n",
       "\n",
       "show containers in storage account"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FileHandling.ls_containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.ls_containers(name_starts_with='easymigrationtest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FileHandling.create_blob_container\" class=\"doc_header\"><code>FileHandling.create_blob_container</code><a href=\"__main__.py#L80\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FileHandling.create_blob_container</code>(**`container_name`**:`str`=*`'9f7305a2-a6c1-4d6d-b03e-7cb71d3d9be3'`*, **`unique`**:`bool`=*`False`*)\n",
       "\n",
       "creates/check for container when ``upload`` is called, but\n",
       "this function can be used seperately to create\n",
       "a new container in isolation within the specific storage account\n",
       "Args:\n",
       "    container_name (str, optional): creates azure blob container name. Defaults to str(uuid.uuid4()).\n",
       "    unique (bool, optional): add a unique tail to container name. Defaults to False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FileHandling.create_blob_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "fh.create_blob_container(container_name='easymigrationtest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove container\n",
    "fh.rm_container(container_name='easymigrationtest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
